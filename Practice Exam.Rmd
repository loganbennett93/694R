---
title: "Practice Exam"
author: "Logan Bennett"
date: "4/12/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(mlogit)
library(tidyverse)
library(modelsummary)
library(haven)
library(knitr)
library(kableExtra)
```

First I need to load in the cars data set and format it in a way that I can perform logit modeling. The first few lines of the reformatted data set are shown below.

```{r cars data}
data(Car, package = "mlogit")
car_mlogit <- Car %>%
  mutate(choice = gsub("choice", "", choice)) %>%
  dfidx( varying = 5:70, shape = "wide", choice = "choice", sep = "")
head(car_mlogit)
```

Now that I have the data set loaded I can create some base models to compare, from which I can iterate different models and seek the one that best fits the data. I am beginning my base analysis on the assumption that people prioritize their choice of vehicle primarily on the type of vehicle they want and their preferred price range. From there I will introduce other important variables that I think will likely influence their choice, such as the fuel type of the vehicle and the range of the vehicle (fuel economy).

```{r base models}
#This model accounts for type and price
base_model <- mlogit(choice ~ type + price | -1, data = car_mlogit)
#This model accounts for type, fuel, and price
M1 <- mlogit(choice ~ type + fuel + price | -1, data = car_mlogit)
#This model accounts for type, price, and range
M2 <- mlogit(choice ~ type + price + range | -1, data = car_mlogit)
#This model accounts for type, fuel, price, and range
M3 <- mlogit(choice ~ type + fuel + price + range | -1, data = car_mlogit)

list(
  "Base Model" = base_model,
  "With Fuel Type" = M1,
  "With Fuel Economy" = M2,
  "With Fuel Type and Economy"  = M3
) %>%
  modelsummary(fmt = "%.5f", stars = TRUE, statistic_vertical = TRUE)
```

The model summary above shows four separate models, the base model being that which includes only type of vehicle and price. The other three models include fuel type, range (fuel economy), and both fuel type and fuel economy, respectively. Because the options for vehicle type were different for each person in the data set, the intercepts would not have provided any meaningful information and they were excluded from the models.

Initial observation of the coefficients in the models make sense. The coefficients corresponding to type in each of the models vary slightly, but they are all significant and the signs of the coefficients indicate the added or reduced utility of each choice. For instance, the coefficients for SUV and sport car are positive, indicating that these choices are more likely to be chosen as they have positive utility for the person choosing a vehicle, whereas the station wagon, truck, and van options indicate negative utility values. In this case, a regular car is used as the reference level, with a modeled utility of 0. The price coefficient is also significant and negative, accurately depicting the fact that people are less likely to choose a vehicle option as price increases. Though the effect is smaller, the utility of an option does increase as the range of the vehicle between refuelings or rechargings increases.

The coefficients for fuel type do vary between the models. In model M1 with type, price, and fuel type considered, there is a negative utility for methanol or compressed natural gas, with coefficient values of **`r round(coef(M1)["fuelmethanol"], 5)`** and **`r round(coef(M1)["fuelcng"], 5)`**, respectively. However, in model M3 with fuel economy included, the utility of both of these fuel types becomes positive, with respective coefficient values of **`r round(coef(M3)["fuelmethanol"], 5)`** and **`r round(coef(M3)["fuelcng"], 5)`**. The methanol coefficient becomes less significant with the addition of the variables as well. Electric vehicles increase in utility when fuel economy is accounted for. It makes sense that based on fuel type alone, these options may not be as desirable due to the lower availability of refueling stations when compared with gas stations. However, when considered jointly with the fuel efficiency of their respective vehicles, methanol and compressed natural gas may be seen as positives.

In deciding which of these models is most representative of the reality, other considerations were made such as transformations of the data. Initial visualizations were performed on the variables to indicate skewness or correlation and no such transform was found to be necessary. However, it seems intuitive to me that the fraction of stations that can refuel or recharge vehicle will be directly related to fuel type, and fuel type may encompass the effects of station.

In further analyzing the models we must consider the statistical goodness of fit. The log likelihood of the models indicate how close the models are to perfect (a perfect model would have a log likelihood of $0$). The log likelihoods of the base model and models M1, M2, and M3 are **`r round(logLik(base_model), 3)`**, **`r round(logLik(M1), 3)`**, **`r round(logLik(M2), 3)`**, and **`r round(logLik(M3), 3)`**, respectively. The log likelihood of model M3, which includes fuel type and fuel economy (range), is higher than all other models. The model with the lowest log likelihood is the base model. These two findings indicate that the addition of the added variables are beneficial to the fit of the model. However, log likelihood ratio tests can provide statistical evidence that this is true. The results from log likelihood tests performed between models M3 and M1 then on models M3 and M2 are shown below, respectively.

```{r log likelihood test base models}
#Create likelihood ratio test table
tibble(
  Hypothesis = c("$H_{0M1}$","$H_{0M2}$"),
  LL_U = rep(M3$logLik, 2),
  LL_R = c(M1$logLik, M2$logLik)
) %>%
  mutate(
    test_stat = -2 * (LL_R - LL_U),
    df = c(1, 3),
    "Crtical Chi-Squared at 99.9% Conf." = qchisq(0.999, df),
    "P-value" = pchisq(test_stat, df, lower.tail = FALSE)
  ) %>%
  kbl(align = 'c', caption = "Likelihood Ratio Test for Hypothesis $H_{0,M1}$ and $H_{0,M2}$") %>%
  kable_styling()
```

The statistical test of the hypothesis that range has no effect has a chi-square value of **178.556**. The critical χ2 with one degree of freedom at 99.9% confidence (or 0.001 level of significance) is **10.83**. Similarly, the statistical test of the hypothesis that fuel has no effect on vehicle choice has a chi-square value of **45.32**. The critical χ2 with three degrees of freedom at 99.9% confidence level (or 0.001 level of significance) is **16.27**.   This means that both null hypotheses can be rejected and the variables of range and fuel type should not be excluded from the final model. I will take model M3 and use it as a base model to iterate other models. A summary of those models is shown below.

```{r iteration 2 models}

M3 <- mlogit(choice ~ type + fuel + price + range | -1, data = car_mlogit)
M4 <- mlogit(choice ~ type + fuel + price + range + acc + speed | -1, data = car_mlogit)
M5 <- mlogit(choice ~ type + fuel + price + range + pollution | -1, data = car_mlogit)
M6 <- mlogit(choice ~ type + fuel + price + range + cost| -1, data = car_mlogit)
M7 <- mlogit(choice ~ type + fuel + price + range + acc + speed + pollution + cost | -1, data = car_mlogit)

list(
  "Fuel Type and Economy" = M3,
  "With Acceleration and Speed" = M4,
  "With Pollution" = M5,
  "With Cost"  = M6,
  "With Acceleration, Speed, Pollution, and Cost" = M7
) %>%
  modelsummary(fmt = "%.5f", stars = TRUE, statistic_vertical = TRUE)
```

Similarly to the previous models, the coefficients for the type of vehicle are all significant and the utilities of the different types hold as before. The fuel type is less significant when considered in conjunction with all models where pollution is included, but compressed natural gas and electric vehicles have positive utility while methanol vehicles have negative utility, though methanol is not significant in most cases. Range and price also maintain expected levels of positive and negative utility, respectively. It is expected that speed would be a plus for some people, indicated by positive coefficients, and that pollution, time to accelerate, and cost are negative, indicated by negative coefficients, all at significant levels. Interesting to me is the fact that it appears the acceleration of a vehicle is more important to people than the maximum speed, indicated by larger coefficients of **`r round(coef(M4)["acc"], 5)`** and **`r round(coef(M7)["acc"], 5)`** when compared to the respective speed coefficients of **`r round(coef(M4)["speed"], 5)`** and **`r round(coef(M7)["speed"], 5)`**.

It again appears from the log likelihood values that the model that includes all the variables may be the most complete, with the lowest value of **`r round(logLik(M7), 3)`** compared to the other model's values shown above. Log likelihood ratio tests between the models with the newly added variables (acceleration and speed, pollution, and cost) and the new base model with fuel type and fuel economy are shown below.

```{r log likelihood test iteration2 models}
#Create likelihood ratio test table
tibble(
  Hypothesis = c("$H_{0M4}$","$H_{0M5}$", "$H_{0M6}$"),
  LL_U = c(M4$logLik, M5$logLik, M6$logLik),
  LL_R = rep(M3$logLik, 3)
) %>%
  mutate(
    test_stat = -2 * (LL_R - LL_U),
    df = c(2, 1, 1),
    "Crtical Chi-Squared at 99.9% Conf." = qchisq(0.999, df),
    "P-value" = pchisq(test_stat, df, lower.tail = FALSE)
  ) %>%
  kbl(align = 'c', caption = "Likelihood Ratio Test for Hypothesis $H_{0,M4}$, $H_{0,M5}$ and $H_{0,M6}$") %>%
  kable_styling()
```

The results of the log likelihood ratio tests can be interpreted in the same way as the similar tests above. The test statistics for the respective tests with 2, 1, and 1 degrees of freedom indicate that the variables should not be excluded from the final model, though pollution is somewhat less critical to include than speed, acceleration, and cost. I will use model M7 that includes all these variables as a base for a final segmentation analysis, shown below.

```{r segmentation, eval = FALSE}
#segmentation example

base_model <- mlogit(chosen ~ tvtt + cost | wkempden, data = sf_work)
withincome <- mlogit(chosen ~ tvtt + cost | hhinc + wkempden, data = sf_work)
highincome <- mlogit(chosen ~ tvtt + cost | hhinc + wkempden, 
                     data = sf_work %>% filter(hhinc > 50))
low_income <- mlogit(chosen ~ tvtt + cost | hhinc + wkempden, 
                     data = sf_work %>% filter(hhinc <= 50))

list(
  "Base" = base_model,
  "Income" = withincome,
  "High Income" = highincome,
  "Low Income"  = low_income
) %>%
  modelsummary(fmt = "%.5f", stars = TRUE, statistic_vertical = TRUE)
```
